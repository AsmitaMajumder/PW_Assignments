{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Question 1:What is a Decision Tree, and how does it work in the context of classification?\n",
        "\n",
        "A Decision Tree is a supervised learning model used for classification and regression. It represents decisions and their possible consequences as a tree structure composed of internal nodes (tests on features), branches (outcomes of tests), and leaf nodes (predicted class or value).\n",
        "In the context of classification, a decision tree works as follows:\n",
        "1.\tRoot node: The tree starts with all training samples at the root.\n",
        "2.\tSplitting: The algorithm chooses a feature and threshold to split the data into subsets that are more homogeneous with respect to the target class. The split is selected by maximizing a measure of purity improvement (e.g., information gain based on entropy, or reduction in Gini impurity).\n",
        "3.\tRepeat recursively: For each child node, the algorithm repeats splitting until a stopping criterion is met (pure node, minimum samples, max depth, or no improvement).\n",
        "4.\tLeaf nodes: When no further splitting is done, a leaf node stores the majority class (or class probabilities) based on the training samples that ended there. For classification, prediction follows a path from the root to a leaf according to the sample’s features."
      ],
      "metadata": {
        "id": "xkz9mrQ0IKKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dsJ3F3ApI5Vl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Question 2: Explain the concepts of Gini Impurity and Entropy as impurity measures. How do they impact the splits in a Decision Tree?\n",
        "Answer:\n",
        "Both Gini Impurity and Entropy are measures of node impurity (how mixed the class labels are). They are used to evaluate how good a split is by computing the impurity before and after the split; a good split reduces impurity significantly.\n",
        "Entropy (Information Theory)\n",
        "\tFor a node with class probabilities\n",
        "\tEntropy is 0 when all samples belong to one class, and maximum when classes are uniformly distributed.\n",
        "\tInformation Gain for a split is the reduction in entropy from parent to children.\n",
        "Gini Impurity\n",
        "\tDefined as: G=1-∑_(k=1)^K p_k^2.\n",
        "\tLike entropy, Gini is 0 for a pure node and increases as class mixing increases.\n",
        "Impact on splits:\n",
        "\tBoth measures generally choose similar splits. Sometimes Gini favors larger partitions and is slightly faster to compute (no logarithm). Entropy (used for information gain) is more theoretically grounded in information theory.\n",
        "\tIn practice, the chosen impurity metric rarely changes final performance much; however, subtle differences can exist in the tree shape and chosen thresholds.\n",
        "When to use which:\n",
        "\tsklearn defaults to Gini for classification (criterion='gini') and 'entropy' if specified. For most use cases, try both if you suspect sensitivity; otherwise Gini is fine.\n"
      ],
      "metadata": {
        "id": "XuNqd_XSI_Bb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Question 3: What is the difference between Pre-Pruning and Post-Pruning in Decision Trees? Give one practical advantage of using each.\n",
        "Answer:\n",
        "Pre-Pruning (Early Stopping): Stop tree growth early by specifying constraints while building the tree. Common pre-pruning hyperparameters include:\n",
        "•\tmax_depth: maximum tree depth\n",
        "•\tmin_samples_split: minimum samples required to split\n",
        "•\tmin_samples_leaf: minimum samples required to be at a leaf\n",
        "•\tmax_leaf_nodes: maximum number of leaf nodes\n",
        "Advantage of Pre-Pruning: Controls tree size during training, reducing overfitting and computation cost; it's simple and prevents unnecessarily complex splits.\n",
        "Post-Pruning (Prune after full growth): Grow a full or large tree and then prune back nodes that do not improve generalization, typically using a validation set or cross-validation. Methods include cost-complexity pruning (e.g., ccp_alpha in scikit-learn) and reduced error pruning.\n",
        "Advantage of Post-Pruning: Potentially yields better generalization since the pruning decisions are made with knowledge of the full tree structure and validation performance, allowing removal of only those branches that truly harm performance\n"
      ],
      "metadata": {
        "id": "ZiA6hZkEJJ5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Question 4: What is Information Gain in Decision Trees, and why is it important for choosing the best split?\n",
        "Answer:\n",
        "Information Gain measures how much a split decreases the impurity (usually entropy) of a node. Formally, for a parent node with entropy H(parent), and two child nodes with entropies H(left)and H(right)and proportions w_left,w_right, the information gain is:\n",
        "IG=H(parent)-(w_left H(left)+w_right H(right)).\n",
        "It is important because:\n",
        "\tIt quantifies the expected reduction in uncertainty about the class label when partitioning by a feature and threshold.\n",
        "\tThe algorithm chooses the split with the highest information gain (or equivalently the largest impurity reduction) at each node.\n",
        "\tHigh information gain means the split creates children that are more homogeneous (closer to pure), which improves classification accuracy.\n"
      ],
      "metadata": {
        "id": "-tbPGRxnJRnj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Question 5: What are some common real-world applications of Decision Trees, and what are their main advantages and limitations?\n",
        "Answer:\n",
        "Applications:\n",
        "•\tFinance: credit scoring, loan default prediction, fraud detection (interpretable rules).\n",
        "•\tHealthcare: disease diagnosis, patient risk stratification (interpretable decision rules useful for clinicians).\n",
        "•\tMarketing: customer segmentation, churn prediction, targeted promotions.\n",
        "•\tManufacturing: fault detection, quality control.\n",
        "•\tOperations: routing/decision policies, rule-based automation.\n",
        "Advantages:\n",
        "•\tInterpretable: easy-to-understand rules and visualizations.\n",
        "•\tHandles numerical and categorical data (with appropriate encodings).\n",
        "•\tNon-parametric: no assumptions about data distributions.\n",
        "•\tFast inference and can handle missing values (to some extent, though scikit-learn requires imputation).\n",
        "Limitations:\n",
        "•\tOverfitting: fully-grown trees often overfit to training data.\n",
        "•\tInstability: small changes in the data can produce very different trees.\n",
        "•\tGreedy splits: the algorithm makes locally optimal choices, which may not be globally optimal.\n",
        "•\tBias toward variables with many levels unless regularized.\n",
        "•\tOften outperformed by ensembles (Random Forest, Gradient Boosting) in predictive accuracy.\n"
      ],
      "metadata": {
        "id": "UIKHqgOhJas7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Question 6: Write a Python program to:\n",
        "● Load the Iris Dataset\n",
        "● Train a Decision Tree Classifier using the Gini criterion\n",
        "● Print the model’s accuracy and feature importances\n"
      ],
      "metadata": {
        "id": "yp0SJEu6JnRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data       # Features\n",
        "y = iris.target     # Target labels\n",
        "\n",
        "# Step 2: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Create a Decision Tree Classifier using the Gini criterion\n",
        "clf = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "\n",
        "# Step 4: Train the classifier\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Make predictions on the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Step 6: Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Step 7: Print accuracy and feature importances\n",
        "print(\"Decision Tree Classifier using Gini Criterion\")\n",
        "print(\"------------------------------------------------\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Feature Importances:\")\n",
        "for feature, importance in zip(iris.feature_names, clf.feature_importances_):\n",
        "    print(f\"{feature}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8fsrXu4KH5P",
        "outputId": "4f7129fe-1367-42f9-c5c3-926ca27abd2e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier using Gini Criterion\n",
            "------------------------------------------------\n",
            "Accuracy: 1.00\n",
            "Feature Importances:\n",
            "sepal length (cm): 0.0000\n",
            "sepal width (cm): 0.0191\n",
            "petal length (cm): 0.8933\n",
            "petal width (cm): 0.0876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Question7: Write a Python program to:\n",
        "● Load the Iris Dataset\n",
        "● Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to\n",
        "a fully-grown tree.\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "AmdyVdfOKUAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Step 2: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Train a Decision Tree with max_depth=3\n",
        "clf_limited = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
        "clf_limited.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Train a fully-grown Decision Tree\n",
        "clf_full = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "clf_full.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Predict on test data\n",
        "y_pred_limited = clf_limited.predict(X_test)\n",
        "y_pred_full = clf_full.predict(X_test)\n",
        "\n",
        "# Step 6: Calculate accuracy\n",
        "accuracy_limited = accuracy_score(y_test, y_pred_limited)\n",
        "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
        "\n",
        "# Step 7: Print results\n",
        "print(\"Decision Tree Classifier Comparison\")\n",
        "print(\"-----------------------------------\")\n",
        "print(f\"Accuracy (max_depth=3): {accuracy_limited:.2f}\")\n",
        "print(f\"Accuracy (fully grown): {accuracy_full:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6xdKE_DKqqO",
        "outputId": "a48282e6-2a62-41f2-a90f-2b5bfcc4d2ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier Comparison\n",
            "-----------------------------------\n",
            "Accuracy (max_depth=3): 1.00\n",
            "Accuracy (fully grown): 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Question 8: Write a Python program to:\n",
        "● Load the California Housing dataset from sklearn\n",
        "● Train a Decision Tree Regressor\n",
        "● Print the Mean Squared Error (MSE) and feature importances\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "oH-0QHtoKsVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Step 1: Load the California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data\n",
        "y = housing.target\n",
        "\n",
        "# Step 2: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Train a Decision Tree Regressor\n",
        "regressor = DecisionTreeRegressor(criterion='squared_error', random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Predict on the test set\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Step 5: Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Step 6: Print MSE and feature importances\n",
        "print(\"Decision Tree Regressor Results\")\n",
        "print(\"--------------------------------\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(\"Feature Importances:\")\n",
        "for feature, importance in zip(housing.feature_names, regressor.feature_importances_):\n",
        "    print(f\"{feature}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ry4Ogs3K2kp",
        "outputId": "f8e3eeec-b53d-4b25-8d43-81a77433ab4c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Regressor Results\n",
            "--------------------------------\n",
            "Mean Squared Error (MSE): 0.5280\n",
            "Feature Importances:\n",
            "MedInc: 0.5235\n",
            "HouseAge: 0.0521\n",
            "AveRooms: 0.0494\n",
            "AveBedrms: 0.0250\n",
            "Population: 0.0322\n",
            "AveOccup: 0.1390\n",
            "Latitude: 0.0900\n",
            "Longitude: 0.0888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Question 9: Write a Python program to:\n",
        "● Load the Iris Dataset\n",
        "● Tune the Decision Tree’s max_depth and min_samples_split using\n",
        "GridSearchCV\n",
        "● Print the best parameters and the resulting model accuracy"
      ],
      "metadata": {
        "id": "ZrhjWm1cK6R3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Step 2: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Define the Decision Tree Classifier\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Step 4: Define the parameter grid for tuning\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5, 6, None],\n",
        "    'min_samples_split': [2, 3, 4, 5, 6, 10]\n",
        "}\n",
        "\n",
        "# Step 5: Use GridSearchCV for hyperparameter tuning\n",
        "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Get the best model and evaluate it\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Step 7: Print results\n",
        "print(\"Decision Tree Classifier - Grid Search Results\")\n",
        "print(\"----------------------------------------------\")\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best Cross-Validation Score: {grid_search.best_score_:.2f}\")\n",
        "print(f\"Test Set Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlqkO4oJK-jn",
        "outputId": "49988230-3ad9-44a0-d588-56a5936d39bd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier - Grid Search Results\n",
            "----------------------------------------------\n",
            "Best Parameters: {'max_depth': 4, 'min_samples_split': 6}\n",
            "Best Cross-Validation Score: 0.94\n",
            "Test Set Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Question 10: Imagine you’re working as a data scientist for a healthcare company that\n",
        "wants to predict whether a patient has a certain disease. You have a large dataset with\n",
        "mixed data types and some missing values.\n",
        "Explain the step-by-step process you would follow to:\n",
        "● Handle the missing values\n",
        "● Encode the categorical features\n",
        "● Train a Decision Tree model\n",
        "● Tune its hyperparameters\n",
        "● Evaluate its performance\n",
        "And describe what business value this model could provide in the real-world\n",
        "setting.\n",
        "\n",
        "\n",
        "Answer:\n",
        "\n",
        "\n",
        "1) Quick data understanding & EDA\n",
        "\n",
        "Inspect data types, class balance (value_counts()), missingness patterns (df.isna().mean()), unique counts for categoricals.\n",
        "\n",
        "Look for target leakage (features that are derived from the target or measured after diagnosis).\n",
        "\n",
        "Visualize distributions, pairwise relationships, and missingness heatmaps.\n",
        "\n",
        "Decide if some columns should be dropped (IDs, high leakage, constant columns).\n",
        "\n",
        "Why: informs choices for imputation, encoding, and evaluation metrics (e.g., heavy class imbalance → different metrics and resampling).\n",
        "\n",
        "2) Handle missing values\n",
        "\n",
        "Principles\n",
        "\n",
        "Determine mechanism (MCAR / MAR / MNAR) qualitatively — affects whether simple imputation is acceptable.\n",
        "\n",
        "Never impute with values derived from the test set (use a pipeline so fit/transform are done only on training data).\n",
        "\n",
        "Use simple methods first: median for numeric (robust to outliers), most_frequent or 'MISSING' token for categoricals.\n",
        "\n",
        "For complex dependencies consider IterativeImputer (model-based) or KNN imputer.\n",
        "\n",
        "Add binary missing indicators (MissingIndicator) when missingness itself is potentially informative.\n",
        "\n",
        "Options\n",
        "\n",
        "Small fraction missing (<~5%): consider dropping rows.\n",
        "\n",
        "Numeric: SimpleImputer(strategy='median') or IterativeImputer.\n",
        "\n",
        "Categorical: SimpleImputer(strategy='constant', fill_value='MISSING') or target/mean encoding for high-cardinality features (careful about leakage).\n",
        "\n",
        "Keep a flag column (<feature>_was_missing) if missingness is correlated with outcome.\n",
        "\n",
        "3) Encode categorical features\n",
        "\n",
        "For decision trees\n",
        "\n",
        "Trees are robust to monotonic transforms, but ordinal codes can inject artificial order. Prefer:\n",
        "\n",
        "OneHotEncoder(handle_unknown='ignore') for low-cardinality categories.\n",
        "\n",
        "Target encoding / leave-one-out / CatBoost encodings for high-cardinality features (with careful cross-validation to avoid leakage).\n",
        "\n",
        "If using libraries that natively support categoricals (CatBoost, LightGBM), consider them — they often perform better and avoid high-dimensional OHE.\n",
        "\n",
        "Why: correct encoding avoids artificial ordering and prevents the model from failing on unseen categories.\n",
        "\n",
        "4) Build a preprocessing + modeling pipeline\n",
        "\n",
        "Use ColumnTransformer to apply different preprocessing to numeric and categorical columns.\n",
        "\n",
        "Compose a pipeline: preprocessor -> estimator so all transformations are done properly per fold (avoids leakage).\n",
        "\n",
        "Example estimator: DecisionTreeClassifier(random_state=42, class_weight='balanced') (use class_weight if imbalance exists).\n",
        "\n",
        "5) Hyperparameter tuning\n",
        "\n",
        "Hyperparameters for Decision Tree to tune\n",
        "\n",
        "max_depth (prevents overfitting)\n",
        "\n",
        "min_samples_split, min_samples_leaf (control complexity)\n",
        "\n",
        "max_features (subset of features considered per split)\n",
        "\n",
        "criterion ('gini' or 'entropy')\n",
        "\n",
        "class_weight (or use sampling techniques)\n",
        "\n",
        "Tuning strategy\n",
        "\n",
        "Use StratifiedKFold and GridSearchCV or RandomizedSearchCV (for large search spaces).\n",
        "\n",
        "Use scoring consistent with business objective: e.g., roc_auc or average_precision (PR-AUC) if classes imbalanced; or custom cost-sensitive scoring.\n",
        "\n",
        "Prefer nested CV when you want an unbiased estimate of generalization while tuning hyperparameters.\n",
        "\n",
        "6) Evaluate performance (clinical emphasis)\n",
        "\n",
        "Metrics: sensitivity (recall) for the positive disease class, specificity, precision (PPV), NPV, F1, ROC-AUC, PR-AUC.\n",
        "\n",
        "Confusion matrix for a chosen threshold; tune threshold using domain costs (false negative > false positive in many diseases).\n",
        "\n",
        "Calibration: check predicted probabilities with calibration curve and Brier score (are probabilities reliable?).\n",
        "\n",
        "Explainability: show tree rules (for small trees), feature_importances_, permutation importance, and SHAP values for local explanations.\n",
        "\n",
        "Validation: holdout test set + external validation on data from other hospitals/populations, and subgroup analysis (by age, sex, ethnicity).\n",
        "\n",
        "Decision curve analysis to measure net clinical benefit across thresholds.\n",
        "\n",
        "7) Deployment & monitoring (operational)\n",
        "\n",
        "Convert pipeline to a reproducible artifact (pickle, joblib, or an ML-serving container) with preprocessing included.\n",
        "\n",
        "Monitor data drift, model performance, and calibration in production; set alerts for performance degradation.\n",
        "\n",
        "Retraining plan (frequency or trigger-based).\n",
        "\n",
        "Auditability, logging, and explainability for clinicians.\n",
        "\n",
        "Privacy & regulatory: HIPAA/GDPR compliance, access controls, and model documentation (Model Card).\n",
        "\n",
        "8) Clinical & business value (with caveats)\n",
        "\n",
        "Value\n",
        "\n",
        "Early detection and triage → faster treatment, reduced morbidity.\n",
        "\n",
        "Risk stratification → prioritize high-risk patients for tests/interventions.\n",
        "\n",
        "Resource optimization → focusing expensive diagnostics on likely positives.\n",
        "\n",
        "Improved patient outcomes and lower long-term costs when combined with clinical pathways.\n",
        "\n",
        "Caveats / Risks\n",
        "\n",
        "False negatives can harm patients; false positives add unnecessary tests/costs and anxiety.\n",
        "\n",
        "Biases in training data can propagate to inequitable care—require subgroup validation and mitigation.\n",
        "\n",
        "Clinical validation and prospective trials often required before deployment.\n",
        "\n",
        "Clinician trust demands interpretability and clear documentation.\n",
        "\n",
        "End-to-end Python example\n",
        "\n",
        "This is a reusable template (adapt df, target_col and column lists). It builds preprocessing pipelines, trains a Decision Tree with GridSearchCV, prints the best params and evaluation metrics, and shows feature importances mapped back to input features.\n",
        "\n",
        "# Example pipeline / tuning code for a mixed-type healthcare dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, roc_auc_score,\n",
        "    average_precision_score, brier_score_loss\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "saYeO9RzLG0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "TmK-xf2nLJ7K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}